name: Get Hot News

on:
  schedule:
    # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
    # â° GitHub Actions å®šæ—¶è§¦å‘ï¼ˆä»…æ§åˆ¶ç¨‹åºå”¤é†’é¢‘ç‡ï¼‰
    # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
    #
    # ğŸ’¡ å·¥ä½œåŸç†ï¼š
    #   - GitHub Actions çš„ cron åªè´Ÿè´£ã€Œå”¤é†’ã€ç¨‹åº
    #   - ç¨‹åºå†…éƒ¨æ ¹æ® config/timeline.yaml å†³å®šã€Œåšä»€ä¹ˆã€
    #   - timeline.yaml æ§åˆ¶ï¼šä»€ä¹ˆæ—¶å€™æ¨é€/AIåˆ†æ/ç”¨ä»€ä¹ˆæŠ¥å‘Šæ¨¡å¼
    #
    # ğŸ”„ æ¨èé…ç½®ï¼š
    #   - é»˜è®¤ï¼šæ¯å°æ—¶è¿è¡Œä¸€æ¬¡ï¼ˆå¦‚æ¯å°æ—¶ç¬¬33åˆ†é’Ÿï¼‰
    #   - èŠ‚çœèµ„æºï¼šæ¯2-4å°æ—¶è¿è¡Œä¸€æ¬¡
    #   - é«˜é¢‘ç›‘æ§ï¼šæ¯30åˆ†é’Ÿè¿è¡Œä¸€æ¬¡
    #
    # ğŸ“ ä¿®æ”¹æ–¹æ³•ï¼šåªæ”¹ç¬¬ä¸€ä¸ªæ•°å­—ï¼ˆ0-59ï¼‰ï¼Œè¡¨ç¤ºæ¯å°æ—¶ç¬¬å‡ åˆ†é’Ÿ
    #
    # ç¤ºä¾‹ï¼š
    #   "15 * * * *"      â†’ æ¯å°æ—¶ç¬¬15åˆ†é’Ÿ
    #   "0 */2 * * *"     â†’ æ¯2å°æ—¶æ•´ç‚¹è¿è¡Œ
    #   "30 8-22 * * *"   â†’ åŒ—äº¬æ—¶é—´ 16:00-06:00 æ¯å°æ—¶ç¬¬30åˆ†é’Ÿ
    #
    # âš ï¸ æ³¨æ„ï¼šGitHub Actions å¯èƒ½æœ‰5-15åˆ†é’Ÿçš„éšæœºå»¶è¿Ÿ
    #
    # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
    - cron: "33 * * * *"

  # æ”¯æŒæ‰‹åŠ¨è§¦å‘ï¼ˆç”¨äºæµ‹è¯•æˆ–ç«‹å³æ›´æ–°ï¼‰
  workflow_dispatch:

concurrency:
  group: crawler-${{ github.ref_name }}
  cancel-in-progress: true

permissions:
  contents: write
  actions: write

jobs:
  crawl:
    runs-on: ubuntu-latest
    timeout-minutes: 15

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
          token: ${{ secrets.GITHUB_TOKEN }}

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.10"
          cache: "pip"

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Verify required files
        run: |
          if [ ! -f config/config.yaml ]; then
            echo "âŒ Error: config/config.yaml not found"
            exit 1
          fi
          if [ ! -f config/frequency_words.txt ]; then
            echo "âŒ Error: config/frequency_words.txt not found"
            exit 1
          fi

      - name: Run crawler and generate report
        env:
          # é€šçŸ¥æ¸ é“é…ç½®
          FEISHU_WEBHOOK_URL: ${{ secrets.FEISHU_WEBHOOK_URL }}
          TELEGRAM_BOT_TOKEN: ${{ secrets.TELEGRAM_BOT_TOKEN }}
          TELEGRAM_CHAT_ID: ${{ secrets.TELEGRAM_CHAT_ID }}
          DINGTALK_WEBHOOK_URL: ${{ secrets.DINGTALK_WEBHOOK_URL }}
          WEWORK_WEBHOOK_URL: ${{ secrets.WEWORK_WEBHOOK_URL }}
          WEWORK_MSG_TYPE: ${{ secrets.WEWORK_MSG_TYPE }}
          EMAIL_FROM: ${{ secrets.EMAIL_FROM }}
          EMAIL_PASSWORD: ${{ secrets.EMAIL_PASSWORD }}
          EMAIL_TO: ${{ secrets.EMAIL_TO }}
          EMAIL_SMTP_SERVER: ${{ secrets.EMAIL_SMTP_SERVER }}
          EMAIL_SMTP_PORT: ${{ secrets.EMAIL_SMTP_PORT }}
          NTFY_TOPIC: ${{ secrets.NTFY_TOPIC }}
          NTFY_SERVER_URL: ${{ secrets.NTFY_SERVER_URL }}
          NTFY_TOKEN: ${{ secrets.NTFY_TOKEN }}
          BARK_URL: ${{ secrets.BARK_URL }}
          SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}
          GENERIC_WEBHOOK_URL: ${{ secrets.GENERIC_WEBHOOK_URL }}
          GENERIC_WEBHOOK_TEMPLATE: ${{ secrets.GENERIC_WEBHOOK_TEMPLATE }}
          # AI é…ç½®
          AI_ANALYSIS_ENABLED: ${{ secrets.AI_ANALYSIS_ENABLED }}
          AI_API_KEY: ${{ secrets.AI_API_KEY }}
          AI_MODEL: ${{ secrets.AI_MODEL }}
          AI_API_BASE: ${{ secrets.AI_API_BASE }}
          # è¿œç¨‹å­˜å‚¨é…ç½®
          S3_BUCKET_NAME: ${{ secrets.S3_BUCKET_NAME }}
          S3_ACCESS_KEY_ID: ${{ secrets.S3_ACCESS_KEY_ID }}
          S3_SECRET_ACCESS_KEY: ${{ secrets.S3_SECRET_ACCESS_KEY }}
          S3_ENDPOINT_URL: ${{ secrets.S3_ENDPOINT_URL }}
          S3_REGION: ${{ secrets.S3_REGION }}
          GITHUB_ACTIONS: true
        run: |
          echo "ğŸ“¡ Starting crawler..."
          python -m trendradar
          echo "âœ… Crawler completed"

      - name: Check if files changed
        id: check_changes
        run: |
          if [ -f "index.html" ]; then
            echo "âœ… index.html generated"
            echo "has_changes=true" >> $GITHUB_OUTPUT
          else
            echo "âš ï¸ No index.html found"
            echo "has_changes=false" >> $GITHUB_OUTPUT
          fi

      - name: Commit and push to master
        if: steps.check_changes.outputs.has_changes == 'true'
        run: |
          git config --local user.name "github-actions[bot]"
          git config --local user.email "github-actions[bot]@users.noreply.github.com"
          
          # æ·»åŠ ç”Ÿæˆçš„æ–‡ä»¶
          git add index.html
          git add output/ || true
          
          # æ£€æŸ¥æ˜¯å¦æœ‰å˜åŒ–
          if git diff --staged --quiet; then
            echo "ğŸ“ No changes to commit"
          else
            # æäº¤å˜åŒ–
            TIMESTAMP=$(TZ=Asia/Shanghai date '+%Y-%m-%d %H:%M:%S')
            git commit -m "ğŸ¤– Auto update news - ${TIMESTAMP}"
            
            # æ¨é€åˆ° master åˆ†æ”¯
            git push origin master
            echo "âœ… Successfully pushed to master branch"
          fi

      - name: Summary
        if: always()
        run: |
          echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
          echo "ğŸ“Š Workflow Summary"
          echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
          if [ -f "index.html" ]; then
            SIZE=$(du -h index.html | cut -f1)
            echo "âœ… HTML Report: $SIZE"
            echo "ğŸŒ Visit: https://${{ github.repository_owner }}.github.io/${{ github.event.repository.name }}/"
          else
            echo "âŒ HTML Report: Not generated"
          fi
          echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
